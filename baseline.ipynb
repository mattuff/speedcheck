{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"22IYkFG9GWNU"},"outputs":[],"source":["import torch as T\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader, random_split\n","\n","from google.colab import drive\n","\n","import numpy as np\n","import pandas as pd\n","\n","import os\n","import time\n","import random"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":822241,"status":"ok","timestamp":1656202830511,"user":{"displayName":"Matt Uffenheimer","userId":"08273244796095023606"},"user_tz":420},"id":"b7R6_wUiWX86","outputId":"e1a7be49-5edf-4f61-acba-ad489cbd3057"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["drive.mount('/content/drive/')\n","!unzip -q drive/MyDrive/data/data3.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qfxz0StraCEf"},"outputs":[],"source":["# https://github.com/ndrplz/ConvLSTM_pytorch/blob/master/convlstm.py\n","\n","\n","class ConvLSTMCell(nn.Module):\n","\n","    def __init__(self, input_dim, hidden_dim, kernel_size, bias):\n","        \"\"\"\n","        Initialize ConvLSTM cell.\n","        Parameters\n","        ----------\n","        input_dim: int\n","            Number of channels of input tensor.\n","        hidden_dim: int\n","            Number of channels of hidden state.\n","        kernel_size: (int, int)\n","            Size of the convolutional kernel.\n","        bias: bool\n","            Whether or not to add the bias.\n","        \"\"\"\n","\n","        super(ConvLSTMCell, self).__init__()\n","\n","        self.input_dim = input_dim\n","        self.hidden_dim = hidden_dim\n","\n","        self.kernel_size = kernel_size\n","        self.padding = kernel_size[0] // 2, kernel_size[1] // 2\n","        self.bias = bias\n","\n","        self.conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n","                              out_channels=4 * self.hidden_dim,\n","                              kernel_size=self.kernel_size,\n","                              padding=self.padding,\n","                              bias=self.bias)\n","\n","    def forward(self, input_tensor, cur_state):\n","        h_cur, c_cur = cur_state\n","\n","        combined = T.cat([input_tensor, h_cur], dim=1)  # concatenate along channel axis\n","\n","        combined_conv = self.conv(combined)\n","        cc_i, cc_f, cc_o, cc_g = T.split(combined_conv, self.hidden_dim, dim=1)\n","        i = T.sigmoid(cc_i)\n","        f = T.sigmoid(cc_f)\n","        o = T.sigmoid(cc_o)\n","        g = T.tanh(cc_g)\n","\n","        c_next = f * c_cur + i * g\n","        h_next = o * T.tanh(c_next)\n","\n","        return h_next, c_next\n","\n","    def init_hidden(self, batch_size, image_size):\n","        height, width = image_size\n","        return (T.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device),\n","                T.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device))\n","\n","\n","class ConvLSTM(nn.Module):\n","\n","    \"\"\"\n","    Parameters:\n","        input_dim: Number of channels in input\n","        hidden_dim: Number of hidden channels\n","        kernel_size: Size of kernel in convolutions\n","        num_layers: Number of LSTM layers stacked on each other\n","        batch_first: Whether or not dimension 0 is the batch or not\n","        bias: Bias or no bias in Convolution\n","        return_all_layers: Return the list of computations for all layers\n","        Note: Will do same padding.\n","    Input:\n","        A tensor of size B, T, C, H, W or T, B, C, H, W\n","    Output:\n","        A tuple of two lists of length num_layers (or length 1 if return_all_layers is False).\n","            0 - layer_output_list is the list of lists of length T of each output\n","            1 - last_state_list is the list of last states\n","                    each element of the list is a tuple (h, c) for hidden state and memory\n","    Example:\n","        >> x = T.rand((32, 10, 64, 128, 128))\n","        >> convlstm = ConvLSTM(64, 16, 3, 1, True, True, False)\n","        >> _, last_states = convlstm(x)\n","        >> h = last_states[0][0]  # 0 for layer index, 0 for h index\n","    \"\"\"\n","\n","    def __init__(self, input_dim, hidden_dim, kernel_size, num_layers,\n","                 batch_first=False, bias=True, return_all_layers=False):\n","        super(ConvLSTM, self).__init__()\n","\n","        self._check_kernel_size_consistency(kernel_size)\n","\n","        # Make sure that both `kernel_size` and `hidden_dim` are lists having len == num_layers\n","        kernel_size = self._extend_for_multilayer(kernel_size, num_layers)\n","        hidden_dim = self._extend_for_multilayer(hidden_dim, num_layers)\n","        if not len(kernel_size) == len(hidden_dim) == num_layers:\n","            raise ValueError('Inconsistent list length.')\n","\n","        self.input_dim = input_dim\n","        self.hidden_dim = hidden_dim\n","        self.kernel_size = kernel_size\n","        self.num_layers = num_layers\n","        self.batch_first = batch_first\n","        self.bias = bias\n","        self.return_all_layers = return_all_layers\n","\n","        cell_list = []\n","        for i in range(0, self.num_layers):\n","            cur_input_dim = self.input_dim if i == 0 else self.hidden_dim[i - 1]\n","\n","            cell_list.append(ConvLSTMCell(input_dim=cur_input_dim,\n","                                          hidden_dim=self.hidden_dim[i],\n","                                          kernel_size=self.kernel_size[i],\n","                                          bias=self.bias))\n","\n","        self.cell_list = nn.ModuleList(cell_list)\n","\n","    def forward(self, input_tensor, hidden_state=None):\n","        \"\"\"\n","        Parameters\n","        ----------\n","        input_tensor: todo\n","            5-D Tensor either of shape (t, b, c, h, w) or (b, t, c, h, w)\n","        hidden_state: todo\n","            None. todo implement stateful\n","        Returns\n","        -------\n","        last_state_list, layer_output\n","        \"\"\"\n","        if not self.batch_first:\n","            # (t, b, c, h, w) -> (b, t, c, h, w)\n","            input_tensor = input_tensor.permute(1, 0, 2, 3, 4)\n","\n","        b, _, _, h, w = input_tensor.size()\n","\n","        # Implement stateful ConvLSTM\n","        if hidden_state is not None:\n","            raise NotImplementedError()\n","        else:\n","            # Since the init is done in forward. Can send image size here\n","            hidden_state = self._init_hidden(batch_size=b,\n","                                             image_size=(h, w))\n","\n","        layer_output_list = []\n","        last_state_list = []\n","\n","        seq_len = input_tensor.size(1)\n","        cur_layer_input = input_tensor\n","\n","        for layer_idx in range(self.num_layers):\n","\n","            h, c = hidden_state[layer_idx]\n","            output_inner = []\n","            for t in range(seq_len):\n","                h, c = self.cell_list[layer_idx](input_tensor=cur_layer_input[:, t, :, :, :],\n","                                                 cur_state=[h, c])\n","                output_inner.append(h)\n","\n","            layer_output = T.stack(output_inner, dim=1)\n","            cur_layer_input = layer_output\n","\n","            layer_output_list.append(layer_output)\n","            last_state_list.append([h, c])\n","\n","        if not self.return_all_layers:\n","            layer_output_list = layer_output_list[-1:]\n","            last_state_list = last_state_list[-1:]\n","\n","        return layer_output_list, last_state_list\n","\n","    def _init_hidden(self, batch_size, image_size):\n","        init_states = []\n","        for i in range(self.num_layers):\n","            init_states.append(self.cell_list[i].init_hidden(batch_size, image_size))\n","        return init_states\n","\n","    @staticmethod\n","    def _check_kernel_size_consistency(kernel_size):\n","        if not (isinstance(kernel_size, tuple) or\n","                (isinstance(kernel_size, list) and all([isinstance(elem, tuple) for elem in kernel_size]))):\n","            raise ValueError('`kernel_size` must be tuple or list of tuples')\n","\n","    @staticmethod\n","    def _extend_for_multilayer(param, num_layers):\n","        if not isinstance(param, list):\n","            param = [param] * num_layers\n","        return param"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GHXukHiF8U6q"},"outputs":[],"source":["\n","class Data(Dataset):\n","\n","  def __init__(self, samples, labels):\n","    self.samples = samples\n","    self.labels = labels\n","    self.len = samples.size(0)\n","  \n","  def __getitem__(self, index):\n","    return self.samples[index, :, :], self.labels[index, :]\n","\n","  def __len__(self):\n","    return self.len\n","\n","\n","class LazyData(Dataset):\n","\n","  def __init__(self, samples_path, labels_path):\n","    self.samples_path = samples_path\n","    self.labels_path = labels_path\n","    self.samples_list = [\n","      filename for filename in \n","      os.listdir(samples_path) if \n","      filename != '.DS_Store'\n","    ]\n","    labels_df = pd.read_csv(labels_path)\n","    self.labels_dict = {\n","      row['filename']: \n","      T.tensor([row['label']], dtype=T.float)\n","      for _, row in labels_df.iterrows()\n","    }\n","    self.len = len(self.samples_list)\n","  \n","  def __getitem__(self, index):\n","    filename = self.samples_list[index]\n","    sample_path = os.path.join(self.samples_path, filename)\n","    sample = T.load(sample_path)\n","    label = self.labels_dict[filename]\n","    return sample, label\n","\n","  def __len__(self):\n","    return self.len\n","\n","\n","class SmallData(Dataset):\n","\n","  def __init__(self, samples_path, labels_path, n_samples=1000):\n","    self.samples_path = samples_path\n","    self.labels_path = labels_path\n","    all_samples_names = sorted(\n","      os.listdir(samples_path),\n","      key=lambda x: int(os.path.splitext(x)[0])\n","    )\n","    all_labels = np.load(labels_path)\n","\n","    self.len = min(n_samples, len(all_samples_names))\n","    keep_indices = random.choices(\n","      range(self.len), \n","      k=n_samples\n","    )\n","\n","    samples_numpy = np.empty((n_samples, 15, 3, 224, 224), dtype=np.single)\n","    labels_numpy = np.empty((n_samples, 1), dtype=np.single)\n","    for i, k in enumerate(keep_indices):\n","      cur_sample_path = os.path.join(samples_path, all_samples_names[k])\n","      cur_sample = np.load(cur_sample_path)\n","      samples_numpy[i] = cur_sample\n","      labels_numpy[i] = all_labels[k]\n","\n","    self.samples = T.as_tensor(samples_numpy)\n","    self.labels = T.as_tensor(labels_numpy)\n","  \n","  def __getitem__(self, index):\n","    sample = self.samples[index]\n","    label = self.labels[index]\n","    return sample, label\n","\n","  def __len__(self):\n","    return self.len\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ouYarQ8WDr5l"},"outputs":[],"source":["def pram():\n","  free, total = T.cuda.mem_get_info()\n","  print(f'{free/1024**2:.2f} free of {total/1024**2:.2f}.')\n","\n","\n","class ConvLSTMBlock(nn.Module):\n","\n","  def __init__(self, input_dim, hidden_dim, num_layers,\n","    conv_kernel_size=(3, 3), pool_kernel_size=(1, 2, 2),\n","    pool_stride=1, activation=F.relu):\n","    \n","    super(ConvLSTMBlock, self).__init__()\n","    self.convlstm = ConvLSTM(\n","      input_dim=input_dim,\n","      hidden_dim=hidden_dim,\n","      kernel_size=conv_kernel_size,\n","      num_layers=num_layers,\n","      bias=True,\n","      batch_first=True\n","    )\n","    self.activation = activation\n","    self.pool = nn.MaxPool3d(\n","      kernel_size=pool_kernel_size,\n","      stride=pool_stride\n","    )\n","  \n","  def forward(self, x):\n","    x = self.convlstm(x)[0][0]\n","    x = T.permute(x, (0, 2, 1, 3, 4))\n","    x = self.activation(x)\n","    x = self.pool(x)\n","    x = T.permute(x, (0, 2, 1, 3, 4))\n","    return x\n","\n","\n","class Model(nn.Module):\n","\n","  def __init__(self):\n","    super(Model, self).__init__()\n","\n","    self.clstm1 = ConvLSTM(\n","      input_dim=3,\n","      hidden_dim=56,\n","      num_layers=1,\n","      kernel_size=(7, 7),\n","      bias=False,\n","      batch_first=True\n","    )\n","    self.pool1 = nn.MaxPool3d(\n","      kernel_size=(1, 4, 4),\n","      stride=(1, 4, 4)\n","    )\n","    self.norm1 = nn.InstanceNorm3d(\n","        num_features=56\n","    )\n","\n","    self.clstm2 = ConvLSTM(\n","      input_dim=56,\n","      hidden_dim=48,\n","      num_layers=1,\n","      kernel_size=(5, 5),\n","      bias=False,\n","      batch_first=True\n","    )\n","    self.pool2 = nn.MaxPool3d(\n","      kernel_size=(1, 4, 4),\n","      stride=(1, 4, 4)\n","    )\n","    self.norm2 = nn.InstanceNorm3d(\n","        num_features=48\n","    )\n","\n","    self.clstm3 = ConvLSTM(\n","      input_dim=48,\n","      hidden_dim=36,\n","      num_layers=1,\n","      kernel_size=(3, 3),\n","      bias=False,\n","      batch_first=True\n","    )\n","    self.pool3 = nn.MaxPool2d(\n","      kernel_size=(2, 2),\n","      stride=(2, 2)\n","    )\n","    self.norm3 = nn.InstanceNorm2d(\n","        num_features=36\n","    )\n","\n","    self.fc1 = nn.Linear(in_features=1764, out_features=512)\n","    self.drop1 = nn.Dropout(p=0.5)\n","    self.fc2 = nn.Linear(in_features=512, out_features=1)\n","  \n","  def forward(self, x):\n","\n","    x = self.clstm1(x)[0][0]\n","    x = T.permute(x, (0, 2, 1, 3, 4))\n","    x = self.pool1(x)\n","    x = self.norm1(x)\n","    x = T.permute(x, (0, 2, 1, 3, 4))\n","    x = F.relu(x)\n","\n","    x = self.clstm2(x)[0][0]\n","    x = T.permute(x, (0, 2, 1, 3, 4))\n","    x = self.pool2(x)\n","    x = self.norm2(x)\n","    x = T.permute(x, (0, 2, 1, 3, 4))\n","    x = F.relu(x)\n","    \n","    x = self.clstm3(x)[0][0]\n","    x = x[:, -1, :, :, :]\n","    x = self.pool3(x)\n","    x = self.norm3(x)\n","    x = F.relu(x)\n","\n","    x = T.flatten(x, start_dim=1)\n","    x = self.fc1(x)\n","    x = F.relu(x)\n","    x = self.drop1(x)\n","    x = self.fc2(x)\n","\n","    return x\n","  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UCe0i-8FjOyk"},"outputs":[],"source":["\n","def train_step(dataloader, device, model, criterion, optimizer):\n","  total_loss = 0\n","  len_counter = 0\n","  for x, y in dataloader:\n","    x = x.to(device)\n","    y = y.to(device)\n","    optimizer.zero_grad()\n","    pred = model(x)\n","    loss = criterion(pred, y)\n","    loss.backward()\n","    optimizer.step()\n","    total_loss += x.size(0) * loss.item()\n","    len_counter += x.size(0)\n","  total_loss /= len_counter\n","  return total_loss\n","\n","\n","def eval_step(dataloader, device, model, criterion):\n","  total_loss = 0\n","  len_counter = 0\n","  with T.no_grad():\n","    for x, y in dataloader:\n","      x = x.to(device)\n","      y = y.to(device)\n","      pred = model(x)\n","      loss = criterion(pred, y)\n","      total_loss += x.size(0) * loss.item() \n","      len_counter += x.size(0)\n","  total_loss /= len_counter\n","  return total_loss\n","\n","\n","def train_loop(device, model, criterion, optimizer,\n","    train_loader, val_loader, test_loader,\n","    scheduler=None, init_epochs=100, add_epochs=False, verbose=False):\n","\n","  model = model.to(device)\n","  if verbose:\n","    print(model)\n","\n","  n_epochs = init_epochs\n","  total_epochs = init_epochs\n","  \n","  while n_epochs:\n","\n","    for epoch in range(n_epochs):\n","\n","      since = time.perf_counter()\n","\n","      model.train()\n","      train_loss = train_step(train_loader, device, model, criterion, optimizer)\n","\n","      model.eval()\n","      val_loss = eval_step(val_loader, device, model, criterion)\n","\n","      if scheduler:\n","        scheduler.step(val_loss)\n","\n","      if verbose:\n","        print(\n","          f'{time.perf_counter() - since:>6.1f}s :: ' +\n","          f'Epoch {total_epochs-n_epochs+epoch+1}/{total_epochs} complete.'\n","        )\n","        free_mem, total_mem = T.cuda.mem_get_info()\n","        print(\n","          ' ' * 11 +\n","          f'Device(free: {free_mem/(1024**2):.3f}, ' +\n","          f'total: {total_mem/(1024**2):.3f}).'\n","        )\n","        print(\n","          ' ' * 11 +\n","          f'Loss(train: {train_loss:.3f}, val: {val_loss:.3f}).'\n","        )\n","\n","    test_loss = eval_step(test_loader, device, model, criterion)\n","\n","    if verbose or add_epochs:\n","      print(f'Test loss: {test_loss}.')\n","    if add_epochs:\n","      n_epochs = input('Add epochs?')\n","      try:\n","        n_epochs = max(0, int(n_epochs))\n","        total_epochs += n_epochs\n","      except ValueError:\n","        n_epochs = 0\n","    else:\n","      n_epochs = 0\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":979,"status":"ok","timestamp":1656203650741,"user":{"displayName":"Matt Uffenheimer","userId":"08273244796095023606"},"user_tz":420},"id":"BuqdzVA5xIvb","outputId":"bb5eb1fa-cafd-4ced-84d5-6b351de70a45"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda.\n"]}],"source":["\n","device0 = T.device('cuda' if T.cuda.is_available() else 'cpu')\n","print(f'Using device: {device0}.')\n","\n","prop_val = 0.2\n","prop_test = 0.2\n","\n","full_dataset = LazyData(\n","  samples_path=os.path.join('data', 'samples'),\n","  labels_path=os.path.join('data', 'labels.csv')\n",")\n","len_val = int(prop_val * len(full_dataset))\n","len_test = int(prop_test * len(full_dataset))\n","len_train = len(full_dataset) - len_val - len_test\n","train, val, test = random_split(\n","  full_dataset, [len_train, len_val, len_test],\n","  generator=T.Generator().manual_seed(4)\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C71rOS3I4aoP","outputId":"a497e204-d3e6-4ad4-9853-4f1ecc01ff52"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model(\n","  (clstm1): ConvLSTM(\n","    (cell_list): ModuleList(\n","      (0): ConvLSTMCell(\n","        (conv): Conv2d(59, 224, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","      )\n","    )\n","  )\n","  (pool1): MaxPool3d(kernel_size=(1, 4, 4), stride=(1, 4, 4), padding=0, dilation=1, ceil_mode=False)\n","  (norm1): InstanceNorm3d(56, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","  (clstm2): ConvLSTM(\n","    (cell_list): ModuleList(\n","      (0): ConvLSTMCell(\n","        (conv): Conv2d(104, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n","      )\n","    )\n","  )\n","  (pool2): MaxPool3d(kernel_size=(1, 4, 4), stride=(1, 4, 4), padding=0, dilation=1, ceil_mode=False)\n","  (norm2): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","  (clstm3): ConvLSTM(\n","    (cell_list): ModuleList(\n","      (0): ConvLSTMCell(\n","        (conv): Conv2d(84, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","    )\n","  )\n","  (pool3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n","  (norm3): InstanceNorm2d(36, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","  (fc1): Linear(in_features=1764, out_features=512, bias=True)\n","  (drop1): Dropout(p=0.5, inplace=False)\n","  (fc2): Linear(in_features=512, out_features=1, bias=True)\n",")\n","2615.7s :: Epoch 1/201 complete.\n","           Device(free: 567.750, total: 16280.875).\n","           Loss(train: 38.067, val: 33.552).\n","2613.2s :: Epoch 2/201 complete.\n","           Device(free: 567.750, total: 16280.875).\n","           Loss(train: 32.131, val: 26.211).\n","2612.1s :: Epoch 3/201 complete.\n","           Device(free: 567.750, total: 16280.875).\n","           Loss(train: 25.162, val: 27.584).\n","2612.3s :: Epoch 4/201 complete.\n","           Device(free: 567.750, total: 16280.875).\n","           Loss(train: 21.573, val: 21.184).\n","2613.1s :: Epoch 5/201 complete.\n","           Device(free: 567.750, total: 16280.875).\n","           Loss(train: 19.646, val: 19.809).\n","2614.0s :: Epoch 6/201 complete.\n","           Device(free: 567.750, total: 16280.875).\n","           Loss(train: 18.299, val: 19.139).\n","2615.1s :: Epoch 7/201 complete.\n","           Device(free: 567.750, total: 16280.875).\n","           Loss(train: 16.867, val: 19.171).\n","2615.5s :: Epoch 8/201 complete.\n","           Device(free: 567.750, total: 16280.875).\n","           Loss(train: 15.801, val: 16.879).\n","2614.9s :: Epoch 9/201 complete.\n","           Device(free: 567.750, total: 16280.875).\n","           Loss(train: 14.313, val: 19.010).\n","2614.5s :: Epoch 10/201 complete.\n","           Device(free: 567.750, total: 16280.875).\n","           Loss(train: 14.585, val: 17.367).\n","2613.5s :: Epoch 11/201 complete.\n","           Device(free: 567.750, total: 16280.875).\n","           Loss(train: 14.686, val: 18.825).\n","2613.8s :: Epoch 12/201 complete.\n","           Device(free: 567.750, total: 16280.875).\n","           Loss(train: 13.832, val: 18.014).\n","2613.7s :: Epoch 13/201 complete.\n","           Device(free: 567.750, total: 16280.875).\n","           Loss(train: 12.979, val: 16.410).\n","2614.2s :: Epoch 14/201 complete.\n","           Device(free: 567.750, total: 16280.875).\n","           Loss(train: 12.727, val: 19.483).\n","2615.0s :: Epoch 15/201 complete.\n","           Device(free: 567.750, total: 16280.875).\n","           Loss(train: 14.415, val: 19.733).\n","2615.5s :: Epoch 16/201 complete.\n","           Device(free: 567.750, total: 16280.875).\n","           Loss(train: 14.233, val: 19.895).\n","2615.2s :: Epoch 17/201 complete.\n","           Device(free: 567.750, total: 16280.875).\n","           Loss(train: 14.251, val: 18.052).\n","2615.5s :: Epoch 18/201 complete.\n","           Device(free: 567.750, total: 16280.875).\n","           Loss(train: 12.211, val: 18.719).\n","2615.2s :: Epoch 19/201 complete.\n","           Device(free: 567.750, total: 16280.875).\n","           Loss(train: 12.117, val: 18.722).\n","2614.7s :: Epoch 20/201 complete.\n","           Device(free: 567.750, total: 16280.875).\n","           Loss(train: 12.882, val: 19.297).\n","2614.9s :: Epoch 21/201 complete.\n","           Device(free: 567.750, total: 16280.875).\n","           Loss(train: 11.840, val: 18.028).\n","2615.3s :: Epoch 22/201 complete.\n","           Device(free: 567.750, total: 16280.875).\n","           Loss(train: 11.863, val: 17.728).\n","2615.1s :: Epoch 23/201 complete.\n","           Device(free: 567.750, total: 16280.875).\n","           Loss(train: 11.902, val: 17.900).\n","Epoch 00024: reducing learning rate of group 0 to 2.7000e-04.\n","2614.7s :: Epoch 24/201 complete.\n","           Device(free: 567.750, total: 16280.875).\n","           Loss(train: 10.748, val: 18.333).\n","2615.2s :: Epoch 25/201 complete.\n","           Device(free: 567.750, total: 16280.875).\n","           Loss(train: 8.969, val: 18.136).\n","2615.5s :: Epoch 26/201 complete.\n","           Device(free: 567.750, total: 16280.875).\n","           Loss(train: 7.831, val: 17.693).\n"]}],"source":["\n","train_loader0 = DataLoader(train, batch_size=8, num_workers=2, shuffle=True)\n","val_loader0 = DataLoader(val, batch_size=8, num_workers=2)\n","test_loader0 = DataLoader(test, batch_size=8, num_workers=2)\n","\n","model0 = Model()\n","\n","# model0 = Model()\n","# model0.load_state_dict(T.load('model_dir/model'))\n","\n","criterion0 = nn.MSELoss()\n","optimizer0 = T.optim.Adam(model0.parameters(), lr=0.0009)\n","scheduler0 = T.optim.lr_scheduler.ReduceLROnPlateau(\n","  optimizer0, factor=0.3, verbose=True, patience=10\n",")\n","\n","train_loop(\n","  device0, model0, criterion0, optimizer0,\n","  train_loader0, val_loader0, test_loader0,\n","  scheduler=scheduler0, add_epochs=True, verbose=True,\n","  init_epochs=201\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8oQFFwYfCU-2"},"outputs":[],"source":["# !mkdir model\n","# T.save(model0.state_dict(), os.path.join('model', 'model'))\n","# T.save(optimizer0.state_dict(), os.path.join('model', 'optimizer'))\n","# !zip -r model.zip model/\n","# !cp model.zip drive/MyDrive/data/"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"baseline.ipynb","provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyONMjiViAPeumn2x7pD3Gs9"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}